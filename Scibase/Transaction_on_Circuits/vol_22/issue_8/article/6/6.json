{"issn": [{"format": "Print ISSN", "value": "1051-8215"}, {"format": "Electronic ISSN", "value": "1558-2205"}],"metrics": {"citationCountPaper": 7, "citationCountPatent": 0, "totalDownloads": 827},"doi": "10.1109/TCSVT.2012.2197080","title": "Near-Duplicate Video Clip Detection Using Model-Free Semantic Concept Detection and Adaptive Semantic Distance Measurement","publicationTitle": "IEEE Transactions on Circuits and Systems for Video Technology","abstract": "Motivated by the observation that content transformations tend to preserve the semantic information conveyed by video clips, this paper introduces a novel technique for near-duplicate video clip (NDVC) detection, leveraging model-free semantic concept detection and adaptive semantic distance measurement. In particular, model-free semantic concept detection is realized by taking advantage of the collective knowledge in an image folksonomy (which is an unstructured collection of user-contributed images and tags), facilitating the use of an unrestricted concept vocabulary. Adaptive semantic distance measurement is realized by means of the signature quadratic form distance (SQFD), making it possible to flexibly measure the similarity between video shots that contain a varying number of semantic concepts, and where these semantic concepts may also differ in terms of relevance and nature. Experimental results obtained for the MIRFLICKR-25000 image set (used as a source of collective knowledge) and the TRECVID 2009 video set (used to create query and reference video clips) demonstrate that model-free semantic concept detection and SQFD can be successfully used for the purpose of identifying NDVCs.","authors": [{"name": "Hyun-seok Min", "affiliation": "Image and Video Systems Laboratory, Korea Advanced Institute of Science and Technology, Daejeon, Korea", "bio": {"graphic": "/mediastore/IEEE/content/freeimages/76/6255841/6193167/6193167-photo-1-small.gif", "p": ["Hyun-seok Min received the B.S. degree from Ajou University, Suwon, Korea, in 2005, and the M.S. degree from the Korea Advanced Institute of Science and Technology (KAIST), Daejeon, Korea, in 2008. He is currently pursuing the Ph.D. degree with KAIST.", "His current research interests include video content identification, video annotation, image and video content analysis, and the semantic and social web."]}}, {"name": "Jae Young Choi", "affiliation": "Image and Video Systems Laboratory, Korea Advanced Institute of Science and Technology, Daejeon, Korea", "bio": {"graphic": "/mediastore/IEEE/content/freeimages/76/6255841/6193167/6193167-photo-2-small.gif", "p": ["Jae Young Choi received the B.S. degree from Kwangwoon University, Seoul, Korea, in 2004, and the M.S. and Ph.D. degrees from the Korea Advanced Institute of Science and Technology (KAIST), Daejeon, Korea, in 2008 and 2011, respectively.", "In 2008, he was a Visiting Researcher with the University of Toronto, Toronto, ON, Canada. He is currently a Post-Doctoral Researcher with KAIST and with the University of Toronto. His current research interests include face recognition, medical image processing, pattern recognition, machine learning, computer vision, and the social web.", "Dr. Choi was the recipient of the Samsung Human Tech Thesis Prize in 2010 for his research on collaborative face recognition using online social network context."]}}, {"name": "Wesley De Neve", "affiliation": "Image and Video Systems Laboratory, Korea Advanced Institute of Science and Technology, Daejeon, Korea", "bio": {"graphic": "/mediastore/IEEE/content/freeimages/76/6255841/6193167/6193167-photo-3-small.gif", "p": ["Wesley De Neve received the M.S. degree in computer science and the Ph.D. degree in computer science engineering from Ghent University, Ghent, Belgium, in 2002 and 2007, respectively.", "He is currently a Research Assistant Professor with the Image and Video Systems Laboratory, Korea Advanced Institute of Science and Technology (KAIST), Daejeon, Korea. Prior to joining KAIST, he was a Post-Doctoral Researcher with Ghent University, and with Information and Communications University, Daejeon. His current research interests include image and video coding, near-duplicate video clip detection, face recognition, privacy-protected video surveillance, and leveraging collective knowledge for the semantic analysis of image and video content."]}}, {"name": "Yong Man Ro", "affiliation": "Image and Video Systems Laboratory, Korea Advanced Institute of Science and Technology, Daejeon, Korea", "bio": {"graphic": "/mediastore/IEEE/content/freeimages/76/6255841/6193167/6193167-photo-4-small.gif", "p": ["Yong Man Ro (M'92\u2013SM'98) received the B.S. degree from Yonsei University, Seoul, Korea, and the M.S. and Ph.D. degrees from the Korea Advanced Institute of Science and Technology (KAIST), Daejeon, Korea.", "In 1987, he was a Visiting Researcher with Columbia University, New York, NY, and from 1992 to 1995, he was a Visiting Researcher with the University of California, Irvine. He was a Research Fellow with the University of California, Berkeley, in 1996, and a Visiting Professor with the University of Toronto, Toronto, ON, Canada, in 2007. He is currently a Full Professor with KAIST, chairing the Image and Video Systems Laboratory. He participated in the MPEG-7 and MPEG-21 international standardization efforts, contributing to the definition of the MPEG-7 texture descriptor, the definition of the MPEG-21 DIA visual impairment descriptors, and modality conversion. His current research interests include image and video processing, multimedia adaptation, visual data mining, image and video indexing, and multimedia security.", "Dr. Ro received the Young Investigator Finalist Award of ISMRM in 1992 and the Scientist of the Year Award in 2003. He was a Technical Program Committee Member of international conferences such as IWDW, WIAMIS, AIRS, and CCNC, and he was the Program Co-Chair of IWDW in 2004."]}}],"keywords": [{"type": "IEEE Keywords", "kwd": ["Semantics", "Visualization", "Feature extraction", "Silicon", "Face", "Adaptation models", "Distance measurement"]}, {"type": "INSPEC: Controlled Indexing", "kwd": ["video signal processing", "content-based retrieval", "knowledge based systems"]}, {"type": "INSPEC: Non-Controlled Indexing", "kwd": ["reference video clip", "near duplicate video clip detection", "model free semantic concept detection", "adaptive semantic distance measurement", "content transformation", "semantic information", "image folksonomy", "user contributed image", "signature quadratic form distance", "MIRFLICKR-25000 image set", "collective knowledge", "TRECVID 2009 video set", "query creation"]}, {"type": "Author Keywords ", "kwd": ["video copy detection", "Collective knowledge", "image folksonomy", "near-duplicate video clip detection", "semantic concept detection", "semantic distance", "semantic video signature"]}],"citations":[{"ieee-citations":[{"authors":["Tang-You Chang","Shen-Chuan Tai","Guo-Shiang Lin"],"article name":"A near-duplicate video retrieval method based on Zernike moments","Journal Name":"Signal and Information Processing Association Annual Summit and Conference (APSIPA) 2015 Asia-Pacific","vol":"none","pp.": "860-864","Year": "2015","ISSN":"none","ISBN":"none"},{"authors":["Cheng Deng","Xu Tang","Junchi Yan","Wei Liu","Xinbo Gao"],"article name":"Discriminative Dictionary Learning With Common Label Alignment for Cross-Modal Retrieval","Journal Name":"Multimedia IEEE Transactions on","vol.": "18","pp.": "208-218","Year": "2016","ISSN": "1520-9210","ISBN":"none"},{"authors":["S. Lameri","P. Bestagini","A. Mellon","S. Milani","A. Rocha","M. Tagliasacchi","S. Tubaro"],"article name":"Who is my parent? Reconstructing video sequences from partially matching shots","Journal Name":"Image Processing (ICIP) 2014 IEEE International Conference on","vol":"none","pp.": "5342-5346","Year": "2014","ISSN":"none","ISBN":"none"},{"authors":["Chien-Li Chou","Hua-Tsung Chen","Suh-Yin Lee"],"article name":"Multimodal Video-to-Near-Scene Annotation","Journal Name":"Multimedia IEEE Transactions on","vol.": "19","pp.": "354-366","Year": "2017","ISSN": "1520-9210","ISBN":"none"}]},{"nonieee-citations":[{"authors":["Zhipeng Wu","Kiyoharu Aizawa"],"article name":"Self-similarity-based partial near-duplicate video retrieval and alignment","Journal Name":"International Journal of Multimedia Information Retrieval","vol.": "3","pp.": "1","Year": "2014","ISSN": "2192-6611","ISBN":"none"},{"authors":["Yonghong Tian","Mengren Qian","Tiejun Huang"],"article name":"TASC","Journal Name":"ACM Transactions on Information Systems","vol.": "33","pp.": "1","Year": "2015","ISSN": "10468188","ISBN":"none"},{"authors":["Semin Kim","Jae Young Choi","Seungwan Han","Yong Man Ro"],"article name":"Adaptive weighted fusion with new spatial and temporal fingerprints for improved video copy detection","Journal Name":"Signal Processing: Image Communication","vol.": "29","pp.": "788","Year": "2014","ISSN": "09235965","ISBN":"none"}]}]}